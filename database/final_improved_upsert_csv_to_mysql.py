#!/usr/bin/env python3
"""
ìµœì¢… ê°œì„ ëœ CSV to MySQL UPSERT ìŠ¤í¬ë¦½íŠ¸ - ì™„ì „í•œ ì¤‘ë³µ ë°©ì§€ ë¡œì§ í¬í•¨
"""
import subprocess
import mysql.connector
from mysql.connector import Error
import pandas as pd
import time
import signal
import os
from datetime import datetime

class FinalImprovedUpsertCSVToMySQL:
    def __init__(self):
        self.ssh_process = None
        self.connection = None
        self.cursor = None
        self.csv_base_path = '/Users/youz2me/Xcode/Livith-Data/output/main_output'

    def create_ssh_tunnel(self):
        """SSH í„°ë„ ìƒì„±"""
        try:
            print("ğŸ”§ SSH í„°ë„ ìƒì„± ì¤‘...")
            
            ssh_command = [
                'ssh',
                '-i', '/Users/youz2me/Downloads/livith-key.pem',
                '-L', '3307:livithdb.c142i2022qs5.ap-northeast-2.rds.amazonaws.com:3306',
                '-N',
                '-o', 'StrictHostKeyChecking=no',
                'ubuntu@43.203.48.65'
            ]
            
            self.ssh_process = subprocess.Popen(
                ssh_command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                preexec_fn=os.setsid
            )
            
            time.sleep(3)
            
            if self.ssh_process.poll() is None:
                print("âœ… SSH í„°ë„ ìƒì„± ì™„ë£Œ!")
                return True
            else:
                return False
                
        except Exception as e:
            print(f"âŒ SSH í„°ë„ ì˜¤ë¥˜: {e}")
            return False

    def connect_mysql(self):
        """MySQL ì—°ê²°"""
        try:
            print("ğŸ”Œ MySQL ì—°ê²° ì¤‘...")
            
            config = {
                'host': '127.0.0.1',
                'port': 3307,
                'user': 'root',
                'password': 'livith0407',
                'database': 'livith_v3',
                'charset': 'utf8mb4',
                'use_unicode': True
            }
            
            self.connection = mysql.connector.connect(**config)
            self.cursor = self.connection.cursor()
            
            print("âœ… MySQL ì—°ê²° ì„±ê³µ!")
            return True
            
        except Error as e:
            print(f"âŒ MySQL ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def clear_result_buffer(self):
        """ê²°ê³¼ ë²„í¼ ì •ë¦¬"""
        try:
            self.cursor.fetchall()
        except:
            pass

    def upsert_md_with_duplicate_prevention(self):
        """md.csv â†’ md í…Œì´ë¸” (ì™„ì „í•œ ì¤‘ë³µ ë°©ì§€)"""
        try:
            print("\nğŸ›ï¸ md.csv UPSERT ì¤‘ (ì¤‘ë³µ ë°©ì§€ ê°•í™”)...")
            
            csv_path = f"{self.csv_base_path}/md.csv"
            if not os.path.exists(csv_path):
                print("  âš ï¸ md.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            df = pd.read_csv(csv_path, encoding='utf-8')
            df = df.fillna('')
            
            print(f"  â€¢ CSV ë ˆì½”ë“œ: {len(df)}ê°œ")
            
            # concert_id ë§¤í•‘
            self.cursor.execute("SELECT id, title FROM concerts")
            concert_mapping = {title: id for id, title in self.cursor.fetchall()}
            self.clear_result_buffer()
            
            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ì„¸íŠ¸
            processed_items = set()
            insert_count = 0
            duplicate_count = 0
            
            for _, row in df.iterrows():
                concert_id = concert_mapping.get(row['concert_title'])
                if not concert_id:
                    continue
                    
                item_name = row['item_name'][:100] if row['item_name'] else ''
                if not item_name:
                    continue
                
                # 1. CSV ë‚´ ì¤‘ë³µ ì²´í¬
                item_key = (concert_id, item_name)
                if item_key in processed_items:
                    duplicate_count += 1
                    continue
                processed_items.add(item_key)
                
                # 2. DB ì¤‘ë³µ ì²´í¬
                self.cursor.execute(
                    "SELECT id FROM md WHERE concert_id = %s AND name = %s",
                    (concert_id, item_name)
                )
                existing = self.cursor.fetchone()
                self.clear_result_buffer()
                
                if existing:
                    duplicate_count += 1
                    continue
                
                # 3. INSERT
                current_time = datetime.now()
                insert_query = """
                    INSERT INTO md (concert_id, name, price, img_url, created_at, updated_at)
                    VALUES (%s, %s, %s, %s, %s, %s)
                """
                
                self.cursor.execute(insert_query, (
                    concert_id,
                    item_name,
                    row.get('price', '')[:30],
                    row.get('img_url', ''),
                    current_time,
                    current_time
                ))
                insert_count += 1
            
            if insert_count > 0:
                self.connection.commit()
            
            print(f"  âœ… md í…Œì´ë¸”: {insert_count}ê°œ ì‚½ì…, {duplicate_count}ê°œ ì¤‘ë³µ ìŠ¤í‚µ")
            return True
            
        except Exception as e:
            print(f"  âŒ md UPSERT ì‹¤íŒ¨: {e}")
            self.connection.rollback()
            return False

    def upsert_schedule_with_duplicate_prevention(self):
        """schedule.csv â†’ schedule í…Œì´ë¸” (ì™„ì „í•œ ì¤‘ë³µ ë°©ì§€)"""
        try:
            print("\nğŸ“… schedule.csv UPSERT ì¤‘ (ì¤‘ë³µ ë°©ì§€ ê°•í™”)...")
            
            csv_path = f"{self.csv_base_path}/schedule.csv"
            if not os.path.exists(csv_path):
                print("  âš ï¸ schedule.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            df = pd.read_csv(csv_path, encoding='utf-8')
            df = df.fillna('')
            
            print(f"  â€¢ CSV ë ˆì½”ë“œ: {len(df)}ê°œ")
            
            # concert_id ë§¤í•‘
            self.cursor.execute("SELECT id, title FROM concerts")
            concert_mapping = {title: id for id, title in self.cursor.fetchall()}
            self.clear_result_buffer()
            
            # scheduled_at ì»¬ëŸ¼ ì²˜ë¦¬
            def parse_scheduled_at(date_str):
                if not date_str:
                    return datetime.now()
                try:
                    for fmt in ['%Y-%m-%d %H:%M:%S', '%Y.%m.%d %H:%M', '%Y-%m-%d', '%Y.%m.%d']:
                        try:
                            return datetime.strptime(date_str, fmt)
                        except:
                            continue
                    return datetime.now()
                except:
                    return datetime.now()
            
            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ì„¸íŠ¸
            processed_items = set()
            insert_count = 0
            duplicate_count = 0
            
            for _, row in df.iterrows():
                concert_id = concert_mapping.get(row['concert_title'])
                if not concert_id:
                    continue
                    
                category = row['category'][:50] if row['category'] else ''
                if not category:
                    continue
                
                # scheduled_at íŒŒì‹±
                scheduled_at = parse_scheduled_at(row.get('scheduled_at', ''))
                scheduled_at_str = scheduled_at.strftime('%Y-%m-%d %H:%M:%S')
                
                # 1. CSV ë‚´ ì¤‘ë³µ ì²´í¬ (concert_id + category + scheduled_at)
                item_key = (concert_id, category, scheduled_at_str)
                if item_key in processed_items:
                    duplicate_count += 1
                    continue
                processed_items.add(item_key)
                
                # 2. DB ì¤‘ë³µ ì²´í¬ (concert_id + category + scheduled_at)
                self.cursor.execute(
                    "SELECT id FROM schedule WHERE concert_id = %s AND category = %s AND scheduled_at = %s",
                    (concert_id, category, scheduled_at)
                )
                existing = self.cursor.fetchone()
                self.clear_result_buffer()
                
                if existing:
                    duplicate_count += 1
                    continue
                
                # 3. INSERT
                current_time = datetime.now()
                schedule_type = row.get('type', 'CONCERT')
                if schedule_type not in ['CONCERT', 'TICKETING']:
                    schedule_type = 'CONCERT'
                
                insert_query = """
                    INSERT INTO schedule (concert_id, category, scheduled_at, type, created_at, updated_at)
                    VALUES (%s, %s, %s, %s, %s, %s)
                """
                
                self.cursor.execute(insert_query, (
                    concert_id,
                    category,
                    scheduled_at,
                    schedule_type,
                    current_time,
                    current_time
                ))
                insert_count += 1
            
            if insert_count > 0:
                self.connection.commit()
            
            print(f"  âœ… schedule í…Œì´ë¸”: {insert_count}ê°œ ì‚½ì…, {duplicate_count}ê°œ ì¤‘ë³µ ìŠ¤í‚µ")
            return True
            
        except Exception as e:
            print(f"  âŒ schedule UPSERT ì‹¤íŒ¨: {e}")
            self.connection.rollback()
            return False

    def upsert_home_concert_sections_with_duplicate_prevention(self):
        """home_concert_sections.csv â†’ home_concert_sections í…Œì´ë¸” (ì™„ì „í•œ ì¤‘ë³µ ë°©ì§€)"""
        try:
            print("\nğŸ  home_concert_sections.csv UPSERT ì¤‘ (ì¤‘ë³µ ë°©ì§€ ê°•í™”)...")
            
            csv_path = f"{self.csv_base_path}/home_concert_sections.csv"
            if not os.path.exists(csv_path):
                print("  âš ï¸ home_concert_sections.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            df = pd.read_csv(csv_path, encoding='utf-8')
            df = df.fillna('')
            
            print(f"  â€¢ CSV ë ˆì½”ë“œ: {len(df)}ê°œ")
            
            # ë§¤í•‘ ë°ì´í„°
            self.cursor.execute("SELECT id, title FROM concerts")
            concert_mapping = {title: id for id, title in self.cursor.fetchall()}
            self.clear_result_buffer()
            
            self.cursor.execute("SELECT id, section_title FROM home_sections")
            home_section_mapping = {title: id for id, title in self.cursor.fetchall()}
            self.clear_result_buffer()
            
            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ì„¸íŠ¸
            processed_items = set()
            insert_count = 0
            duplicate_count = 0
            
            for _, row in df.iterrows():
                concert_id = concert_mapping.get(row['concert_title'])
                section_id = home_section_mapping.get(row['section_title'])
                
                if not concert_id or not section_id:
                    continue
                
                # 1. CSV ë‚´ ì¤‘ë³µ ì²´í¬ (section_id + concert_id ì¡°í•©)
                item_key = (section_id, concert_id)
                if item_key in processed_items:
                    duplicate_count += 1
                    continue
                processed_items.add(item_key)
                
                # 2. DB ì¤‘ë³µ ì²´í¬
                self.cursor.execute(
                    "SELECT id FROM home_concert_sections WHERE home_section_id = %s AND concert_id = %s",
                    (section_id, concert_id)
                )
                existing = self.cursor.fetchone()
                self.clear_result_buffer()
                
                if existing:
                    duplicate_count += 1
                    continue
                
                # 3. INSERT
                current_time = datetime.now()
                sorted_index = len(processed_items)  # ìˆœì„œëŒ€ë¡œ ì¸ë±ìŠ¤ í• ë‹¹
                
                insert_query = """
                    INSERT INTO home_concert_sections 
                    (home_section_id, concert_id, section_title, concert_title, sorted_index, created_at, updated_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                """
                
                self.cursor.execute(insert_query, (
                    section_id,
                    concert_id,
                    row['section_title'],
                    row['concert_title'],
                    sorted_index,
                    current_time,
                    current_time
                ))
                insert_count += 1
            
            if insert_count > 0:
                self.connection.commit()
            
            print(f"  âœ… home_concert_sections í…Œì´ë¸”: {insert_count}ê°œ ì‚½ì…, {duplicate_count}ê°œ ì¤‘ë³µ ìŠ¤í‚µ")
            return True
            
        except Exception as e:
            print(f"  âŒ home_concert_sections UPSERT ì‹¤íŒ¨: {e}")
            self.connection.rollback()
            return False

    def upsert_search_concert_sections_with_duplicate_prevention(self):
        """search_concert_sections.csv â†’ search_concert_sections í…Œì´ë¸” (ì™„ì „í•œ ì¤‘ë³µ ë°©ì§€)"""
        try:
            print("\nğŸ” search_concert_sections.csv UPSERT ì¤‘ (ì¤‘ë³µ ë°©ì§€ ê°•í™”)...")
            
            csv_path = f"{self.csv_base_path}/search_concert_sections.csv"
            if not os.path.exists(csv_path):
                print("  âš ï¸ search_concert_sections.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            df = pd.read_csv(csv_path, encoding='utf-8')
            df = df.fillna('')
            
            print(f"  â€¢ CSV ë ˆì½”ë“œ: {len(df)}ê°œ")
            
            # ë§¤í•‘ ë°ì´í„°
            self.cursor.execute("SELECT id, title FROM concerts")
            concert_mapping = {title: id for id, title in self.cursor.fetchall()}
            self.clear_result_buffer()
            
            self.cursor.execute("SELECT id, section_title FROM search_sections")
            search_section_mapping = {title: id for id, title in self.cursor.fetchall()}
            self.clear_result_buffer()
            
            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ì„¸íŠ¸
            processed_items = set()
            insert_count = 0
            duplicate_count = 0
            
            for _, row in df.iterrows():
                concert_id = concert_mapping.get(row['concert_title'])
                section_id = search_section_mapping.get(row['section_title'])
                
                if not concert_id or not section_id:
                    continue
                
                # 1. CSV ë‚´ ì¤‘ë³µ ì²´í¬ (section_id + concert_id ì¡°í•©)
                item_key = (section_id, concert_id)
                if item_key in processed_items:
                    duplicate_count += 1
                    continue
                processed_items.add(item_key)
                
                # 2. DB ì¤‘ë³µ ì²´í¬
                self.cursor.execute(
                    "SELECT id FROM search_concert_sections WHERE search_section_id = %s AND concert_id = %s",
                    (section_id, concert_id)
                )
                existing = self.cursor.fetchone()
                self.clear_result_buffer()
                
                if existing:
                    duplicate_count += 1
                    continue
                
                # 3. INSERT
                current_time = datetime.now()
                sorted_index = len(processed_items)  # ìˆœì„œëŒ€ë¡œ ì¸ë±ìŠ¤ í• ë‹¹
                
                insert_query = """
                    INSERT INTO search_concert_sections 
                    (search_section_id, concert_id, section_title, concert_title, sorted_index, created_at, updated_at)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                """
                
                self.cursor.execute(insert_query, (
                    section_id,
                    concert_id,
                    row['section_title'],
                    row['concert_title'],
                    sorted_index,
                    current_time,
                    current_time
                ))
                insert_count += 1
            
            if insert_count > 0:
                self.connection.commit()
            
            print(f"  âœ… search_concert_sections í…Œì´ë¸”: {insert_count}ê°œ ì‚½ì…, {duplicate_count}ê°œ ì¤‘ë³µ ìŠ¤í‚µ")
            return True
            
        except Exception as e:
            print(f"  âŒ search_concert_sections UPSERT ì‹¤íŒ¨: {e}")
            self.connection.rollback()
            return False

    def close_connections(self):
        """ì—°ê²° ì¢…ë£Œ"""
        try:
            if self.cursor:
                self.cursor.close()
            if self.connection:
                self.connection.close()
            if self.ssh_process:
                os.killpg(os.getpgid(self.ssh_process.pid), signal.SIGTERM)
            print("\nğŸ”’ ëª¨ë“  ì—°ê²° ì¢…ë£Œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ì—°ê²° ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")

    def run_duplicate_prone_tables_only(self):
        """ì¤‘ë³µ ë¬¸ì œê°€ ìˆëŠ” í…Œì´ë¸”ë§Œ ì²˜ë¦¬"""
        try:
            print("\n" + "="*70)
            print("ğŸš€ ì¤‘ë³µ ë°©ì§€ ê°•í™” UPSERT (ë¬¸ì œ í…Œì´ë¸”ë§Œ)")
            print("="*70)
            
            # SSH í„°ë„ ìƒì„±
            if not self.create_ssh_tunnel():
                print("âŒ SSH í„°ë„ ìƒì„± ì‹¤íŒ¨")
                return
            
            # MySQL ì—°ê²°
            if not self.connect_mysql():
                print("âŒ MySQL ì—°ê²° ì‹¤íŒ¨")
                return
            
            print("\n" + "="*50)
            print("ğŸ“Š ì¤‘ë³µ ë°©ì§€ ê°•í™” í…Œì´ë¸” ì²˜ë¦¬")
            print("="*50)
            
            # ì¤‘ë³µ ë¬¸ì œê°€ ìˆëŠ” í…Œì´ë¸”ë“¤ë§Œ ì²˜ë¦¬
            success_count = 0
            total_count = 4
            
            if self.upsert_md_with_duplicate_prevention():
                success_count += 1
                
            if self.upsert_schedule_with_duplicate_prevention():
                success_count += 1
                
            if self.upsert_home_concert_sections_with_duplicate_prevention():
                success_count += 1
                
            if self.upsert_search_concert_sections_with_duplicate_prevention():
                success_count += 1
            
            print("\n" + "="*70)
            print(f"âœ… ì¤‘ë³µ ë°©ì§€ ê°•í™” ì²˜ë¦¬ ì™„ë£Œ! ({success_count}/{total_count})")
            print("="*70)
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            self.close_connections()

if __name__ == "__main__":
    upserter = FinalImprovedUpsertCSVToMySQL()
    upserter.run_duplicate_prone_tables_only()