import pandas as pd
import os
import logging
from typing import List, Dict, Any
from data_processing.data_models import *
from data_processing.enhanced_data_collector import EnhancedDataCollector
from utils.config import Config
from utils.safe_writer import SafeWriter

logger = logging.getLogger(__name__)

class EnhancedCSVManager:
    @staticmethod
    def ensure_output_dir():
        if not os.path.exists(Config.OUTPUT_DIR):
            os.makedirs(Config.OUTPUT_DIR)
    
    @staticmethod
    def save_all_data(collected_data: List[Dict[str, Any]]):
        """ëª¨ë“  ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥ (append ëª¨ë“œ)"""
        EnhancedCSVManager.ensure_output_dir()
        
        # ê° ë°ì´í„° íƒ€ì…ë³„ë¡œ ìˆ˜ì§‘
        all_concerts = []
        all_setlists = []
        all_concert_setlists = []
        all_setlist_songs = []
        all_songs = []
        all_cultures = []
        all_schedules = []
        all_merchandise = []
        all_concert_info = []
        all_artists = []
        
        for data in collected_data:
            if data['concert']:
                all_concerts.append(data['concert'])
            all_setlists.extend(data['setlists'])
            all_concert_setlists.extend(data['concert_setlists'])
            all_setlist_songs.extend(data['setlist_songs'])
            all_songs.extend(data['songs'])
            all_cultures.extend(data['cultures'])
            all_schedules.extend(data['schedules'])
            all_merchandise.extend(data['merchandise'])
            all_concert_info.extend(data['concert_info'])
            if data['artist']:
                all_artists.append(data['artist'])
        
        # ì½˜ì„œíŠ¸ ë°ì´í„° ì •ë ¬
        if all_concerts:
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            existing_concerts = EnhancedCSVManager._load_existing_data("concerts.csv")
            
            # ìŠ¤ë§ˆíŠ¸ ë³‘í•©: KOPIS ë°ì´í„°ëŠ” ë³´ì¡´í•˜ê³  ìƒˆ í•„ë“œëŠ” ì—…ë°ì´íŠ¸
            merged_concerts = {}
            
            # ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¨¼ì € ì €ì¥ (KOPIS ë°ì´í„° í¬í•¨)
            for concert in existing_concerts:
                merged_concerts[concert.title] = concert
            
            # ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ (KOPIS ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë³´ì¡´)
            for new_concert in all_concerts:
                if new_concert.title in merged_concerts:
                    # ê¸°ì¡´ ì½˜ì„œíŠ¸ê°€ ìˆìœ¼ë©´ KOPIS ë°ì´í„°ëŠ” ë³´ì¡´í•˜ê³  ìƒˆ í•„ë“œë§Œ ì—…ë°ì´íŠ¸
                    existing = merged_concerts[new_concert.title]
                    merged_concerts[new_concert.title] = Concert(
                        artist=existing.artist,  # ê¸°ì¡´ ê°’ ìœ ì§€
                        code=existing.code or new_concert.code,  # ê¸°ì¡´ ê°’ì´ ìˆìœ¼ë©´ ìš°ì„ , ì—†ìœ¼ë©´ ìƒˆ ê°’
                        title=new_concert.title,
                        start_date=existing.start_date or new_concert.start_date,
                        end_date=existing.end_date or new_concert.end_date,
                        status=new_concert.status,  # ìƒíƒœëŠ” ìƒˆ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                        poster=existing.poster or new_concert.poster,  # KOPIS ë°ì´í„° ë³´ì¡´
                        ticket_site=existing.ticket_site or new_concert.ticket_site,  # KOPIS ë°ì´í„° ë³´ì¡´
                        ticket_url=existing.ticket_url or new_concert.ticket_url,  # KOPIS ë°ì´í„° ë³´ì¡´
                        venue=existing.venue or new_concert.venue,  # KOPIS ë°ì´í„° ë³´ì¡´
                        label=new_concert.label,  # ìƒˆ í•„ë“œëŠ” ì—…ë°ì´íŠ¸
                        introduction=new_concert.introduction  # ìƒˆ í•„ë“œëŠ” ì—…ë°ì´íŠ¸
                    )
                else:
                    # ìƒˆ ì½˜ì„œíŠ¸ë©´ ê·¸ëŒ€ë¡œ ì¶”ê°€
                    merged_concerts[new_concert.title] = new_concert
            
            unique_concerts = list(merged_concerts.values())
            
            # ì½˜ì„œíŠ¸ ì •ë ¬
            sorted_concerts = EnhancedDataCollector.sort_concerts(unique_concerts)
            
            # ì „ì²´ ë°ì´í„°ë¡œ ì½˜ì„œíŠ¸ ì €ì¥ (overwrite)
            EnhancedCSVManager._save_to_csv(sorted_concerts, "concerts.csv", "ì½˜ì„œíŠ¸", mode="overwrite")
        
        # ë‚˜ë¨¸ì§€ ë°ì´í„°ëŠ” append ëª¨ë“œë¡œ ì €ì¥
        EnhancedCSVManager._append_to_csv(all_setlists, "setlists.csv", "ì…‹ë¦¬ìŠ¤íŠ¸")
        EnhancedCSVManager._append_to_csv(all_concert_setlists, "concert_setlists.csv", "ì½˜ì„œíŠ¸-ì…‹ë¦¬ìŠ¤íŠ¸")
        EnhancedCSVManager._append_to_csv(all_setlist_songs, "setlist_songs.csv", "ì…‹ë¦¬ìŠ¤íŠ¸ ê³¡")
        EnhancedCSVManager._append_to_csv(all_songs, "songs.csv", "ê³¡")
        EnhancedCSVManager._append_to_csv(all_cultures, "cultures.csv", "ë¬¸í™”")
        EnhancedCSVManager._append_to_csv(all_schedules, "schedule.csv", "ìŠ¤ì¼€ì¤„")
        EnhancedCSVManager._append_to_csv(all_merchandise, "md.csv", "MD")
        EnhancedCSVManager._append_to_csv(all_concert_info, "concert_info.csv", "ì½˜ì„œíŠ¸ ì •ë³´")
        EnhancedCSVManager._append_to_csv(all_artists, "artists.csv", "ì•„í‹°ìŠ¤íŠ¸")
    
    @staticmethod
    def _load_existing_data(filename: str) -> List[Concert]:
        """ê¸°ì¡´ CSV ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ Concert ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        filepath = os.path.join(Config.OUTPUT_DIR, filename)
        if not os.path.exists(filepath):
            return []
        
        try:
            df = pd.read_csv(filepath, encoding='utf-8-sig')
            # NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ì¹˜í™˜
            df = df.fillna('')
            
            concerts = []
            for _, row in df.iterrows():
                concert = Concert(
                    artist=str(row.get('artist', '')),
                    code=str(row.get('code', '')),
                    title=str(row.get('title', '')),
                    start_date=str(row.get('start_date', '')),
                    end_date=str(row.get('end_date', '')),
                    status=str(row.get('status', '')),
                    poster=str(row.get('poster', '')),
                    ticket_site=str(row.get('ticket_site', '')),
                    ticket_url=str(row.get('ticket_url', '')),
                    venue=str(row.get('venue', '')),
                    label=str(row.get('label', '')),
                    introduction=str(row.get('introduction', ''))
                )
                concerts.append(concert)
            return concerts
        except Exception as e:
            logger.error(f"ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    @staticmethod
    def _save_to_csv(data: List, filename: str, description: str, mode: str = "overwrite"):
        """CSV ì €ì¥ ê³µí†µ ë©”ì„œë“œ - ë°ì´í„° ëª¨ë¸ í•„ë“œë§Œ ì €ì¥"""
        if not data:
            logger.warning(f"{description} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        filepath = os.path.join(Config.OUTPUT_DIR, filename)
        
        # ë°ì´í„° ëª¨ë¸ì˜ í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ DataFrame ìƒì„±
        clean_data = []
        for item in data:
            if hasattr(item, '__dataclass_fields__'):
                # dataclass ê°ì²´ì¸ ê²½ìš° ì •ì˜ëœ í•„ë“œë§Œ ì¶”ì¶œ
                item_dict = {}
                for field_name in item.__dataclass_fields__.keys():
                    value = getattr(item, field_name, '')
                    
                    # debut_dateëŠ” ì´ë¯¸ ë¬¸ìì—´ì´ë¯€ë¡œ íŠ¹ë³„í•œ ì²˜ë¦¬ ë¶ˆí•„ìš”
                    
                    item_dict[field_name] = value
                clean_data.append(item_dict)
            else:
                # ì¼ë°˜ ê°ì²´ì¸ ê²½ìš° vars() ì‚¬ìš©
                item_data = vars(item).copy()
                
                # debut_dateëŠ” ì´ë¯¸ ë¬¸ìì—´ì´ë¯€ë¡œ íŠ¹ë³„í•œ ì²˜ë¦¬ ë¶ˆí•„ìš”
                
                clean_data.append(item_data)
        
        df = pd.DataFrame(clean_data)
        
        # ë©”ì¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ì¸ ê²½ìš° ë°±ì—… ìƒì„±
        if Config.OUTPUT_DIR == Config.MAIN_OUTPUT_DIR and os.path.exists(filepath):
            backup_path = SafeWriter._create_backup_if_needed(filename)
            if backup_path:
                logger.info(f"ğŸ“‹ ë°±ì—… ìƒì„±: {os.path.basename(backup_path)}")
        
        df.to_csv(
            filepath,
            index=False,
            encoding='utf-8-sig',
            escapechar='\\',
            quoting=0  # QUOTE_MINIMALë¡œ ë³€ê²½ (í•„ìš”í•œ ê²½ìš°ì—ë§Œ ë”°ì˜´í‘œ ì‚¬ìš©)
        )
        
        logger.info(f"ğŸ’¾ {description} ë°ì´í„°ë¥¼ {filepath}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤. ({len(data)}ê°œ)")

    @staticmethod
    def _append_to_csv(data: List, filename: str, description: str):
        """CSVì— ë°ì´í„° ì¶”ê°€ (ì¤‘ë³µ ì œê±°)"""
        if not data:
            logger.warning(f"{description} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        filepath = os.path.join(Config.OUTPUT_DIR, filename)
        
        # ë°ì´í„° ëª¨ë¸ì˜ í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ DataFrame ìƒì„±
        clean_data = []
        for item in data:
            if hasattr(item, '__dataclass_fields__'):
                # dataclass ê°ì²´ì¸ ê²½ìš° ì •ì˜ëœ í•„ë“œë§Œ ì¶”ì¶œ
                item_dict = {}
                for field_name in item.__dataclass_fields__.keys():
                    value = getattr(item, field_name, '')
                    
                    # debut_dateëŠ” ì´ë¯¸ ë¬¸ìì—´ì´ë¯€ë¡œ íŠ¹ë³„í•œ ì²˜ë¦¬ ë¶ˆí•„ìš”
                    
                    item_dict[field_name] = value
                clean_data.append(item_dict)
            else:
                # ì¼ë°˜ ê°ì²´ì¸ ê²½ìš° vars() ì‚¬ìš©
                item_data = vars(item).copy()
                
                # debut_dateëŠ” ì´ë¯¸ ë¬¸ìì—´ì´ë¯€ë¡œ íŠ¹ë³„í•œ ì²˜ë¦¬ ë¶ˆí•„ìš”
                
                clean_data.append(item_data)
        
        new_df = pd.DataFrame(clean_data)
        
        # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œí•´ì„œ ë³‘í•©
        if os.path.exists(filepath):
            try:
                existing_df = pd.read_csv(filepath, encoding='utf-8-sig')
                # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ í‚¤ ìƒì„± (ì²« ë²ˆì§¸ ì»¬ëŸ¼ ê¸°ì¤€)
                if not existing_df.empty and not new_df.empty:
                    key_column = new_df.columns[0]
                    if key_column in existing_df.columns:
                        # ë°ì´í„° ì—…ì„œíŠ¸ (ì¤‘ë³µì‹œ ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸)
                        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                        combined_df = combined_df.drop_duplicates(subset=[key_column], keep='last')
                    else:
                        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                else:
                    combined_df = new_df
            except Exception as e:
                logger.error(f"ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                combined_df = new_df
        else:
            combined_df = new_df
        
        # ë©”ì¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ì¸ ê²½ìš° ë°±ì—… ìƒì„±
        if Config.OUTPUT_DIR == Config.MAIN_OUTPUT_DIR and os.path.exists(filepath):
            backup_path = SafeWriter._create_backup_if_needed(filename)
            if backup_path:
                logger.info(f"ğŸ“‹ ë°±ì—… ìƒì„±: {os.path.basename(backup_path)}")
        
        combined_df.to_csv(
            filepath,
            index=False,
            encoding='utf-8-sig',
            escapechar='\\',
            quoting=0  # QUOTE_MINIMALë¡œ ë³€ê²½ (í•„ìš”í•œ ê²½ìš°ì—ë§Œ ë”°ì˜´í‘œ ì‚¬ìš©)
        )
        
        logger.info(f"ğŸ’¾ {description} ë°ì´í„°ë¥¼ {filepath}ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ({len(data)}ê°œ ì¶”ê°€, ì´ {len(combined_df)}ê°œ)")
