import pandas as pd
import os
import logging
from typing import List, Dict, Any
from data_processing.data_models import *
from data_processing.enhanced_data_collector import EnhancedDataCollector
from utils.config import Config
from utils.safe_writer import SafeWriter

logger = logging.getLogger(__name__)

class EnhancedCSVManager:
    @staticmethod
    def ensure_output_dir():
        if not os.path.exists(Config.OUTPUT_DIR):
            os.makedirs(Config.OUTPUT_DIR)
    
    @staticmethod
    def save_all_data(collected_data: List[Dict[str, Any]]):
        """ëª¨ë“  ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥ (append ëª¨ë“œ)"""
        EnhancedCSVManager.ensure_output_dir()
        
        # ê° ë°ì´í„° íƒ€ì…ë³„ë¡œ ìˆ˜ì§‘
        all_concerts = []
        all_setlists = []
        all_concert_setlists = []
        all_setlist_songs = []
        all_songs = []
        all_cultures = []
        all_schedules = []
        all_merchandise = []
        all_concert_info = []
        all_artists = []
        
        for data in collected_data:
            if data['concert']:
                all_concerts.append(data['concert'])
            all_setlists.extend(data['setlists'])
            all_concert_setlists.extend(data['concert_setlists'])
            all_setlist_songs.extend(data['setlist_songs'])
            all_songs.extend(data['songs'])
            all_cultures.extend(data['cultures'])
            all_schedules.extend(data['schedules'])
            all_merchandise.extend(data['merchandise'])
            all_concert_info.extend(data['concert_info'])
            if data['artist']:
                all_artists.append(data['artist'])
        
        # ì½˜ì„œíŠ¸ ë°ì´í„°ì— sorted_index ê³„ì‚°
        if all_concerts:
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            existing_concerts = EnhancedCSVManager._load_existing_data("concerts.csv")
            
            # ìƒˆ ë°ì´í„°ì™€ ê¸°ì¡´ ë°ì´í„° ë³‘í•©
            combined_concerts = existing_concerts + all_concerts
            
            # ì¤‘ë³µ ì œê±° (title ê¸°ì¤€)
            unique_concerts = []
            seen_titles = set()
            for concert in combined_concerts:
                if concert.title not in seen_titles:
                    unique_concerts.append(concert)
                    seen_titles.add(concert.title)
            
            # sorted_index ê³„ì‚°
            sorted_concerts = EnhancedDataCollector.calculate_sorted_indices(unique_concerts)
            
            # ì „ì²´ ë°ì´í„°ë¡œ ì½˜ì„œíŠ¸ ì €ì¥ (overwrite)
            EnhancedCSVManager._save_to_csv(sorted_concerts, "concerts.csv", "ì½˜ì„œíŠ¸", mode="overwrite")
        
        # ë‚˜ë¨¸ì§€ ë°ì´í„°ëŠ” append ëª¨ë“œë¡œ ì €ì¥
        EnhancedCSVManager._append_to_csv(all_setlists, "setlists.csv", "ì…‹ë¦¬ìŠ¤íŠ¸")
        EnhancedCSVManager._append_to_csv(all_concert_setlists, "concert_setlists.csv", "ì½˜ì„œíŠ¸-ì…‹ë¦¬ìŠ¤íŠ¸")
        EnhancedCSVManager._append_to_csv(all_setlist_songs, "setlist_songs.csv", "ì…‹ë¦¬ìŠ¤íŠ¸ ê³¡")
        EnhancedCSVManager._append_to_csv(all_songs, "songs.csv", "ê³¡")
        EnhancedCSVManager._append_to_csv(all_cultures, "cultures.csv", "ë¬¸í™”")
        EnhancedCSVManager._append_to_csv(all_schedules, "schedule.csv", "ìŠ¤ì¼€ì¤„")
        EnhancedCSVManager._append_to_csv(all_merchandise, "md.csv", "MD")
        EnhancedCSVManager._append_to_csv(all_concert_info, "concert_info.csv", "ì½˜ì„œíŠ¸ ì •ë³´")
        EnhancedCSVManager._append_to_csv(all_artists, "artists.csv", "ì•„í‹°ìŠ¤íŠ¸")
    
    @staticmethod
    def _load_existing_data(filename: str) -> List[Concert]:
        """ê¸°ì¡´ CSV ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ Concert ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        filepath = os.path.join(Config.OUTPUT_DIR, filename)
        if not os.path.exists(filepath):
            return []
        
        try:
            df = pd.read_csv(filepath, encoding='utf-8-sig')
            concerts = []
            for _, row in df.iterrows():
                concert = Concert(
                    artist=row.get('artist', ''),  # ê¸°ì¡´ artist_display ë‚´ìš©
                    code=row.get('code', ''),
                    title=row.get('title', ''),
                    start_date=row.get('start_date', ''),
                    end_date=row.get('end_date', ''),
                    status=row.get('status', ''),
                    poster=row.get('poster', ''),
                    sorted_index=int(row.get('sorted_index', 0)),
                    ticket_site=row.get('ticket_site', ''),
                    ticket_url=row.get('ticket_url', ''),
                    venue=row.get('venue', '')
                )
                concerts.append(concert)
            return concerts
        except Exception as e:
            logger.error(f"ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    @staticmethod
    def _save_to_csv(data: List, filename: str, description: str, mode: str = "overwrite"):
        """CSV ì €ì¥ ê³µí†µ ë©”ì„œë“œ - ë°ì´í„° ëª¨ë¸ í•„ë“œë§Œ ì €ì¥"""
        if not data:
            logger.warning(f"{description} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        filepath = os.path.join(Config.OUTPUT_DIR, filename)
        
        # ë°ì´í„° ëª¨ë¸ì˜ í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ DataFrame ìƒì„±
        clean_data = []
        for item in data:
            if hasattr(item, '__dataclass_fields__'):
                # dataclass ê°ì²´ì¸ ê²½ìš° ì •ì˜ëœ í•„ë“œë§Œ ì¶”ì¶œ
                item_dict = {}
                for field_name in item.__dataclass_fields__.keys():
                    value = getattr(item, field_name, '')
                    
                    # debut_dateëŠ” ì´ë¯¸ ë¬¸ìì—´ì´ë¯€ë¡œ íŠ¹ë³„í•œ ì²˜ë¦¬ ë¶ˆí•„ìš”
                    
                    item_dict[field_name] = value
                clean_data.append(item_dict)
            else:
                # ì¼ë°˜ ê°ì²´ì¸ ê²½ìš° vars() ì‚¬ìš©
                item_data = vars(item).copy()
                
                # debut_dateëŠ” ì´ë¯¸ ë¬¸ìì—´ì´ë¯€ë¡œ íŠ¹ë³„í•œ ì²˜ë¦¬ ë¶ˆí•„ìš”
                
                clean_data.append(item_data)
        
        df = pd.DataFrame(clean_data)
        
        # ë©”ì¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ì¸ ê²½ìš° ë°±ì—… ìƒì„±
        if Config.OUTPUT_DIR == Config.MAIN_OUTPUT_DIR and os.path.exists(filepath):
            backup_path = SafeWriter._create_backup_if_needed(filename)
            if backup_path:
                logger.info(f"ğŸ“‹ ë°±ì—… ìƒì„±: {os.path.basename(backup_path)}")
        
        df.to_csv(
            filepath,
            index=False,
            encoding='utf-8-sig',
            escapechar='\\',
            quoting=0  # QUOTE_MINIMALë¡œ ë³€ê²½ (í•„ìš”í•œ ê²½ìš°ì—ë§Œ ë”°ì˜´í‘œ ì‚¬ìš©)
        )
        
        logger.info(f"ğŸ’¾ {description} ë°ì´í„°ë¥¼ {filepath}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤. ({len(data)}ê°œ)")

    @staticmethod
    def _append_to_csv(data: List, filename: str, description: str):
        """CSVì— ë°ì´í„° ì¶”ê°€ (ì¤‘ë³µ ì œê±°)"""
        if not data:
            logger.warning(f"{description} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        filepath = os.path.join(Config.OUTPUT_DIR, filename)
        
        # ë°ì´í„° ëª¨ë¸ì˜ í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ DataFrame ìƒì„±
        clean_data = []
        for item in data:
            if hasattr(item, '__dataclass_fields__'):
                # dataclass ê°ì²´ì¸ ê²½ìš° ì •ì˜ëœ í•„ë“œë§Œ ì¶”ì¶œ
                item_dict = {}
                for field_name in item.__dataclass_fields__.keys():
                    value = getattr(item, field_name, '')
                    
                    # debut_dateëŠ” ì´ë¯¸ ë¬¸ìì—´ì´ë¯€ë¡œ íŠ¹ë³„í•œ ì²˜ë¦¬ ë¶ˆí•„ìš”
                    
                    item_dict[field_name] = value
                clean_data.append(item_dict)
            else:
                # ì¼ë°˜ ê°ì²´ì¸ ê²½ìš° vars() ì‚¬ìš©
                item_data = vars(item).copy()
                
                # debut_dateëŠ” ì´ë¯¸ ë¬¸ìì—´ì´ë¯€ë¡œ íŠ¹ë³„í•œ ì²˜ë¦¬ ë¶ˆí•„ìš”
                
                clean_data.append(item_data)
        
        new_df = pd.DataFrame(clean_data)
        
        # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œí•´ì„œ ë³‘í•©
        if os.path.exists(filepath):
            try:
                existing_df = pd.read_csv(filepath, encoding='utf-8-sig')
                # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ í‚¤ ìƒì„± (ì²« ë²ˆì§¸ ì»¬ëŸ¼ ê¸°ì¤€)
                if not existing_df.empty and not new_df.empty:
                    key_column = new_df.columns[0]
                    if key_column in existing_df.columns:
                        # ë°ì´í„° ì—…ì„œíŠ¸ (ì¤‘ë³µì‹œ ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸)
                        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                        combined_df = combined_df.drop_duplicates(subset=[key_column], keep='last')
                    else:
                        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                else:
                    combined_df = new_df
            except Exception as e:
                logger.error(f"ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                combined_df = new_df
        else:
            combined_df = new_df
        
        # ë©”ì¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ì¸ ê²½ìš° ë°±ì—… ìƒì„±
        if Config.OUTPUT_DIR == Config.MAIN_OUTPUT_DIR and os.path.exists(filepath):
            backup_path = SafeWriter._create_backup_if_needed(filename)
            if backup_path:
                logger.info(f"ğŸ“‹ ë°±ì—… ìƒì„±: {os.path.basename(backup_path)}")
        
        combined_df.to_csv(
            filepath,
            index=False,
            encoding='utf-8-sig',
            escapechar='\\',
            quoting=0  # QUOTE_MINIMALë¡œ ë³€ê²½ (í•„ìš”í•œ ê²½ìš°ì—ë§Œ ë”°ì˜´í‘œ ì‚¬ìš©)
        )
        
        logger.info(f"ğŸ’¾ {description} ë°ì´í„°ë¥¼ {filepath}ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ({len(data)}ê°œ ì¶”ê°€, ì´ {len(combined_df)}ê°œ)")
